{
 "metadata": {
  "name": "check-grad"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from active_pmf import *", 
      "import pickle", 
      "import scipy.optimize"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "data = pickle.load(open('../results/10x10_r4_k4_K36/run1/data.pkl', 'rb'))", 
      "apmf = ActivePMF(data['_ratings'], 1, data['_rating_vals'], True)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 46
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def stack_ll(u, v):", 
      "    return np.hstack((u.reshape(-1), v.reshape(-1)))", 
      "", 
      "def unstack_ll(x, n, m, d):", 
      "    return x[:n*d].reshape(n, d), x[n*d:].reshape(m, d)", 
      "", 
      "def ll(apmf):", 
      "    n = apmf.num_users", 
      "    m = apmf.num_items", 
      "    d = apmf.latent_d", 
      "    def inner(x):", 
      "        return apmf.log_likelihood(*unstack_ll(x, n, m, d))", 
      "    return inner", 
      "", 
      "def grad(apmf):", 
      "    n = apmf.num_users", 
      "    m = apmf.num_items", 
      "    d = apmf.latent_d", 
      "    a = deepcopy(apmf)", 
      "    def inner(x):", 
      "        a.users, a.items = unstack_ll(x, n, m, d)", 
      "        return stack(*a.gradient())", 
      "    return inner"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 55
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "scipy.optimize.check_grad(ll(apmf), grad(apmf), stack_ll(apmf.users, apmf.items))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 86, 
       "text": [
        "1.7946174276512887e-06"
       ]
      }
     ], 
     "prompt_number": 86
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def stack_kl(mean, cov):", 
      "    return np.hstack((mean, cov[np.triu_indices_from(cov)]))", 
      "", 
      "def unstack_kl(x, k):", 
      "    cov = np.zeros((k,k))", 
      "    cov[np.triu_indices_from(cov)] = x[k:]", 
      "    cov += cov.T # symmetrize", 
      "    cov[np.diag_indices_from(cov)] /= 2 # correct diagonal", 
      "    return x[:k], cov", 
      "", 
      "def kl(apmf):", 
      "    k = apmf.approx_dim", 
      "    def inner(x):", 
      "        mean, cov = unstack_kl(x, k)", 
      "        if np.any(cov != cov.T) or np.any(scipy.linalg.eigvalsh(cov) <= 0):", 
      "            raise ValueError(\"covariance must be positive definite\")", 
      "        return apmf.kl_divergence(mean, cov)", 
      "    return inner", 
      "", 
      "def grad_kl(apmf):", 
      "    k = apmf.approx_dim", 
      "    a = deepcopy(apmf)", 
      "    def inner(x):", 
      "        a.mean, a.cov = unstack_kl(x, k)", 
      "        return stack_kl(*normal_gradient(a))", 
      "    return inner"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 95
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "apmf.initialize_approx()", 
      "x_kl = stack_kl(apmf.mean, apmf.cov)", 
      "scipy.optimize.check_grad(kl(apmf), grad_kl(apmf), x_kl)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 103, 
       "text": [
        "75247.429984377712"
       ]
      }
     ], 
     "prompt_number": 103
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "approx = scipy.optimize.approx_fprime(x_kl, kl(apmf), np.sqrt(np.finfo(float).eps))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 104
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "calc = grad_kl(apmf)(x_kl)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 105
    }
   ]
  }
 ]
}