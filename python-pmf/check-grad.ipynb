{
 "metadata": {
  "name": "check-grad"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "from copy import deepcopy", 
      "import pickle", 
      "", 
      "import numpy as np", 
      "from scipy.optimize import check_grad, approx_fprime", 
      "import scipy.linalg", 
      "", 
      "import active_pmf", 
      "import normal_exps as nexps", 
      "import normal_exps_cy as nexps_cy", 
      "import pmf_cy", 
      "import pmf as pmf_pure"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "data = pickle.load(open('../results/10x10_r4_d4_k4_K36/run1/data.pkl', 'rb'))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "def stack_ll(u, v):", 
      "    return np.hstack((u.reshape(-1), v.reshape(-1)))", 
      "", 
      "def unstack_ll(x, n, m, d):", 
      "    return x[:n*d].reshape(n, d), x[n*d:].reshape(m, d)", 
      "", 
      "def ll(pmf):", 
      "    n = pmf.num_users", 
      "    m = pmf.num_items", 
      "    d = pmf.latent_d", 
      "    def inner(x):", 
      "        return pmf.log_likelihood(*unstack_ll(x, n, m, d))", 
      "    return inner", 
      "", 
      "def grad(pmf):", 
      "    n = pmf.num_users", 
      "    m = pmf.num_items", 
      "    d = pmf.latent_d", 
      "    a = deepcopy(pmf)", 
      "    def inner(x):", 
      "        a.users, a.items = unstack_ll(x, n, m, d)", 
      "        return stack_ll(*a.gradient())", 
      "    return inner"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "for p in (pmf_pure, pmf_cy):", 
      "    for sub_mean in (False, True):", 
      "        pmf = p.ProbabilisticMatrixFactorization(data['_ratings'], 1, sub_mean)", 
      "        x_ll = stack_ll(pmf.users, pmf.items)", 
      "        print(check_grad(ll(pmf), grad(pmf), x_ll))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "1.16061945673e-06", 
        "2.22894644722e-07", 
        "1.77014239506e-06", 
        "6.3325465453e-07"
       ]
      }
     ], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "def stack_kl(mean, cov):", 
      "    return np.hstack((mean, cov[np.triu_indices_from(cov)]))", 
      "", 
      "def unstack_kl(x, k):", 
      "    cov = np.zeros((k,k))", 
      "    cov[np.triu_indices_from(cov)] = x[k:]", 
      "    cov += cov.T # symmetrize", 
      "    cov[np.diag_indices_from(cov)] /= 2 # correct diagonal", 
      "    return x[:k], cov", 
      "", 
      "def kl(apmf):", 
      "    k = apmf.approx_dim", 
      "    def inner(x):", 
      "        mean, cov = unstack_kl(x, k)", 
      "        if np.any(cov != cov.T) or np.any(scipy.linalg.eigvalsh(cov) <= 0):", 
      "            raise ValueError(\"covariance must be positive definite\")", 
      "        return apmf.kl_divergence(mean, cov)", 
      "    return inner", 
      "", 
      "def grad_kl(apmf, norm_grad=nexps.normal_gradient):", 
      "    k = apmf.approx_dim", 
      "    a = deepcopy(apmf)", 
      "    def inner(x):", 
      "        a.mean, a.cov = unstack_kl(x, k)", 
      "        return stack_kl(*norm_grad(a))", 
      "    return inner"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# (to reload after changes)", 
      "from imp import reload; reload(nexps); reload(nexps_cy); reload(pmf_pure); reload(pmf_cy); reload(active_pmf)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 75, 
       "text": [
        "&lt;module &apos;active_pmf&apos; from &apos;active_pmf.py&apos;&gt;"
       ]
      }
     ], 
     "prompt_number": 75
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "apmf = active_pmf.ActivePMF(data['_ratings'], 1, data['_rating_vals'], True)", 
      "apmf.initialize_approx()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "x_kl = stack_kl(apmf.mean, apmf.cov)", 
      "check_grad(kl(apmf), grad_kl(apmf, nexps.normal_gradient), x_kl)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 7, 
       "text": [
        "290.36898722560812"
       ]
      }
     ], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "approx = approx_fprime(x_kl, kl(apmf), np.sqrt(np.finfo(float).eps))", 
      "calc = grad_kl(apmf, nexps_cy.normal_gradient)(x_kl)", 
      "np.mean(np.abs((calc - approx) / calc))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 8, 
       "text": [
        "0.008934941158440797"
       ]
      }
     ], 
     "prompt_number": 8
    }
   ]
  }
 ]
}