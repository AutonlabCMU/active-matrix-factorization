{
 "metadata": {
  "name": "check-grad"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from copy import deepcopy\n",
      "import pickle\n",
      "\n",
      "import numpy as np\n",
      "from scipy.optimize import check_grad, approx_fprime\n",
      "import scipy.linalg\n",
      "\n",
      "import active_pmf\n",
      "import normal_exps as nexps\n",
      "import normal_exps_cy as nexps_cy\n",
      "import matrix_normal_exps_cy as mnexps_cy\n",
      "import mn_active_pmf\n",
      "import pmf_cy\n",
      "import pmf as pmf_pure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pickle.load(open('../results/10x10_r4_d4_k4_K36/run1/data.pkl', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def stack_ll(u, v):\n",
      "    return np.hstack((u.reshape(-1), v.reshape(-1)))\n",
      "\n",
      "def unstack_ll(x, n, m, d):\n",
      "    return x[:n*d].reshape(n, d), x[n*d:].reshape(m, d)\n",
      "\n",
      "def ll(pmf):\n",
      "    n = pmf.num_users\n",
      "    m = pmf.num_items\n",
      "    d = pmf.latent_d\n",
      "    def inner(x):\n",
      "        return pmf.log_likelihood(*unstack_ll(x, n, m, d))\n",
      "    return inner\n",
      "\n",
      "def grad(pmf):\n",
      "    n = pmf.num_users\n",
      "    m = pmf.num_items\n",
      "    d = pmf.latent_d\n",
      "    a = deepcopy(pmf)\n",
      "    def inner(x):\n",
      "        a.users, a.items = unstack_ll(x, n, m, d)\n",
      "        return stack_ll(*a.gradient())\n",
      "    return inner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in (pmf_pure, pmf_cy):\n",
      "    for sub_mean in (False, True):\n",
      "        pmf = p.ProbabilisticMatrixFactorization(data['_ratings'], 1, sub_mean)\n",
      "        x_ll = stack_ll(pmf.users, pmf.items)\n",
      "        print(check_grad(ll(pmf), grad(pmf), x_ll))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.90201301852e-06\n",
        "3.29453086977e-07\n",
        "1.88000559389e-06\n",
        "4.34644867091e-07\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def stack_kl(mean, cov):\n",
      "    return np.hstack((mean, cov[np.triu_indices_from(cov)]))\n",
      "\n",
      "def unstack_kl(x, k):\n",
      "    cov = np.zeros((k,k))\n",
      "    cov[np.triu_indices_from(cov)] = x[k:]\n",
      "    cov += cov.T # symmetrize\n",
      "    cov[np.diag_indices_from(cov)] /= 2 # correct diagonal\n",
      "    return x[:k], cov\n",
      "\n",
      "def kl(apmf):\n",
      "    k = apmf.approx_dim\n",
      "    def inner(x):\n",
      "        mean, cov = unstack_kl(x, k)\n",
      "        if np.any(cov != cov.T) or np.any(scipy.linalg.eigvalsh(cov) <= 0):\n",
      "            raise ValueError(\"covariance must be positive definite\")\n",
      "        return apmf.kl_divergence(mean, cov)\n",
      "    return inner\n",
      "\n",
      "def grad_kl(apmf, norm_grad=nexps.normal_gradient):\n",
      "    k = apmf.approx_dim\n",
      "    a = deepcopy(apmf)\n",
      "    def inner(x):\n",
      "        a.mean, a.cov = unstack_kl(x, k)\n",
      "        return stack_kl(*norm_grad(a))\n",
      "    return inner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# (to reload after changes)\n",
      "from imp import reload\n",
      "reload(nexps); reload(nexps_cy); reload(mnexps_cy)\n",
      "reload(pmf_pure); reload(pmf_cy)\n",
      "reload(active_pmf); reload(mn_active_pmf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<module 'mn_active_pmf' from './mn_active_pmf.py'>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "apmf = active_pmf.ActivePMF(data['_ratings'], 1, data['_rating_vals'], True)\n",
      "apmf.initialize_approx()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_kl = stack_kl(apmf.mean, apmf.cov)\n",
      "check_grad(kl(apmf), grad_kl(apmf, nexps.normal_gradient), x_kl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "295.00451836754723"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "approx = approx_fprime(x_kl, kl(apmf), np.sqrt(np.finfo(float).eps))\n",
      "calc = grad_kl(apmf, nexps_cy.normal_gradient)(x_kl)\n",
      "np.mean(np.abs((calc - approx) / calc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.0078302104927496004"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stack_mn_kl(mean, cov_useritems, cov_latents):\n",
      "    return np.hstack((mean.ravel(),\n",
      "                      cov_useritems[np.triu_indices_from(cov_useritems)],\n",
      "                      cov_latents[np.triu_indices_from(cov_latents)]))\n",
      "\n",
      "def _unstack_cov(vals, dim):\n",
      "    cov = np.zeros((dim, dim))\n",
      "    cov[np.triu_indices_from(cov)] = vals\n",
      "    cov += cov.T\n",
      "    cov[np.diag_indices_from(cov)] /= 2\n",
      "    return cov\n",
      "\n",
      "def unstack_mn_kl(x, n_useritems, latent_d):\n",
      "    num_mean = n_useritems * latent_d\n",
      "    num_useritems = n_useritems * (n_useritems + 1) // 2\n",
      "    num_latents = latent_d * (latent_d + 1) // 2\n",
      "    assert num_mean + num_useritems + num_latents == x.size, \\\n",
      "           (num_mean, num_useritems, num_latents, x.size)\n",
      "    \n",
      "    mean = x[:num_mean].reshape((n_useritems, latent_d))\n",
      "    cov_useritems = _unstack_cov(x[num_mean:-num_latents], n_useritems)\n",
      "    cov_latents = _unstack_cov(x[-num_latents:], latent_d)\n",
      "    return mean, cov_useritems, cov_latents\n",
      "\n",
      "def _check_cov(cov):\n",
      "    if np.any(cov != cov.T) or np.any(scipy.linalg.eigvalsh(cov) <= 0):\n",
      "       raise ValueError(\"covariance must be positive definite\")\n",
      "    \n",
      "def mn_kl(mn_apmf):\n",
      "    n_useritems = mn_apmf.num_users + mn_apmf.num_items\n",
      "    latent_d = mn_apmf.latent_d\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        return mn_apmf.kl_divergence(mean, cov_useritems, cov_latents)\n",
      "    return inner\n",
      "\n",
      "def grad_mn_kl(mn_apmf, norm_grad=mnexps_cy.matrixnormal_gradient):\n",
      "    n_useritems = mn_apmf.num_users + mn_apmf.num_items\n",
      "    a = deepcopy(mn_apmf)\n",
      "    def inner(x):\n",
      "        a.mean, a.cov_useritems, a.cov_latents = unstack_mn_kl(x, n_useritems, a.latent_d)\n",
      "        return stack_mn_kl(*norm_grad(a))\n",
      "    return inner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnapmf = mn_active_pmf.MNActivePMF(data['_ratings'], 2, data['_rating_vals'], True)\n",
      "mnapmf.initialize_approx(random_cov=True)\n",
      "np.linalg.eigvalsh(mnapmf.cov_useritems), np.linalg.eigvalsh(mnapmf.cov_latents)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(array([  7.17346404e-03,   1.28274715e-01,   2.37682024e-01,\n",
        "         9.47558727e-01,   3.01013569e+00,   4.49390802e+00,\n",
        "         5.98717914e+00,   6.62986197e+00,   8.13915503e+00,\n",
        "         1.01339330e+01,   1.60341971e+01,   1.78555847e+01,\n",
        "         2.17449703e+01,   2.42339960e+01,   2.97760928e+01,\n",
        "         3.15654642e+01,   3.81569793e+01,   4.40635216e+01,\n",
        "         5.13381329e+01,   6.40600520e+01]),\n",
        " array([ 0.00650655,  2.07422675]))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quadexp(n_users, n_items, latent_d, i, j, k, l, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    j_ = n_users + j\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        #cov_useritems = active_pmf.project_psd(cov_useritems, min_eig=1e-3)\n",
      "        #cov_latents = active_pmf.project_psd(cov_latents, min_eig=1e-3)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        return mnexps_cy.quadexpect(mean, cov_useritems, cov_latents,\n",
      "                                    i, k,  j_, k,  i, l,  j_, l) * mult\n",
      "    return inner\n",
      "\n",
      "def grad_quadexp(n_users, n_items, latent_d, i, j, k, l, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        g_mean = np.zeros_like(mean)\n",
      "        g_cov_useritems = np.zeros_like(cov_useritems)\n",
      "        g_cov_latents = np.zeros_like(cov_latents)\n",
      "        mnexps_cy._quadexp_grad(n_users, mean, cov_useritems, cov_latents,\n",
      "                                g_mean, g_cov_useritems, g_cov_latents,\n",
      "                                i, j, k, l, mult)\n",
      "        return stack_mn_kl(g_mean, g_cov_useritems, g_cov_latents)\n",
      "    return inner\n",
      "\n",
      "\n",
      "i = 4\n",
      "j = 1\n",
      "k = 0\n",
      "l = 1\n",
      "\n",
      "quad = quadexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "g_quad = grad_quadexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "\n",
      "x_mn_kl = stack_mn_kl(mnapmf.mean, mnapmf.cov_useritems, mnapmf.cov_latents)\n",
      "\n",
      "approx = approx_fprime(x_mn_kl, quad, np.sqrt(np.finfo(float).eps))\n",
      "calc = g_quad(x_mn_kl)\n",
      "\n",
      "idx = (calc != 0) | (approx != 0)\n",
      "np.vstack((# np.arange(approx.size)[idx], \n",
      "           approx[idx], calc[idx])).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[  -66.83996582,   -66.8399917 ],\n",
        "       [  -10.72058105,   -10.72068997],\n",
        "       [  -34.99182129,   -34.99188246],\n",
        "       [   39.05834961,    39.05832168],\n",
        "       [  179.57897949,   179.57891358],\n",
        "       [  346.31652832,   346.31651931],\n",
        "       [  152.25085449,   152.2508345 ],\n",
        "       [  158.47131348,   158.47132305],\n",
        "       [-3311.99206543, -3311.99214757],\n",
        "       [  604.68823242,   604.68812988]])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.transpose(np.triu_indices(mnapmf.num_users + mnapmf.num_items)) \\\n",
      "    [61 - (mnapmf.num_users + mnapmf.num_items) * mnapmf.latent_d]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([1, 2])"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sqexp(n_users, n_items, latent_d, i, j, k, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    j_ = n_users + j\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        #cov_useritems = active_pmf.project_psd(cov_useritems, min_eig=1e-3)\n",
      "        #cov_latents = active_pmf.project_psd(cov_latents, min_eig=1e-3)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        return mnexps_cy.exp_squared(mean, cov_useritems, cov_latents,\n",
      "                                    i, k,  j_, k) * mult\n",
      "    return inner\n",
      "\n",
      "def grad_sqexp(n_users, n_items, latent_d, i, j, k, mult=1):\n",
      "    n_useritems = n_users + n_items\n",
      "    def inner(x):\n",
      "        mean, cov_useritems, cov_latents = unstack_mn_kl(x, n_useritems, latent_d)\n",
      "        _check_cov(cov_useritems)\n",
      "        _check_cov(cov_latents)\n",
      "        g_mean = np.zeros_like(mean)\n",
      "        g_cov_useritems = np.zeros_like(cov_useritems)\n",
      "        g_cov_latents = np.zeros_like(cov_latents)\n",
      "        mnexps_cy._squareexp_grad(n_users, mean, cov_useritems, cov_latents,\n",
      "                                g_mean, g_cov_useritems, g_cov_latents,\n",
      "                                i, j, k, mult)\n",
      "        return stack_mn_kl(g_mean, g_cov_useritems, g_cov_latents)\n",
      "    return inner\n",
      "\n",
      "\n",
      "i = 4\n",
      "j = 1\n",
      "k = 0\n",
      "\n",
      "f = sqexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "g = grad_sqexp(mnapmf.num_users, mnapmf.num_items, mnapmf.latent_d, i, j, k, l)\n",
      "\n",
      "x_mn_kl = stack_mn_kl(mnapmf.mean, mnapmf.cov_useritems, mnapmf.cov_latents)\n",
      "\n",
      "approx = approx_fprime(x_mn_kl, f, np.sqrt(np.finfo(float).eps))\n",
      "calc = g(x_mn_kl)\n",
      "\n",
      "idx = ((calc != 0) | (approx != 0)) & (np.isfinite(approx) | (calc != 0))\n",
      "np.vstack((# np.arange(approx.size)[idx], \n",
      "           approx[idx], calc[idx])).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([[  156.64111328,   156.64142309],\n",
        "       [  132.19628906,   132.19644855],\n",
        "       [ 1002.65576172,  1002.65603923],\n",
        "       [ 1580.71606445,  1580.71623417],\n",
        "       [  856.06347656,   856.06370602],\n",
        "       [ 9066.7043457 ,  9066.70418788]])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_mn_kl = stack_mn_kl(mnapmf.mean, mnapmf.cov_useritems, mnapmf.cov_latents)\n",
      "approx = approx_fprime(x_mn_kl, mn_kl(mnapmf), np.sqrt(np.finfo(float).eps))\n",
      "calc = grad_mn_kl(mnapmf, mnexps_cy.matrixnormal_gradient)(x_mn_kl)\n",
      "np.mean((np.abs((calc - approx) / calc))[calc != 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.00011969052877497818"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.max(np.abs((calc - approx) / calc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.0038858987793552011"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_useritems = mnapmf.num_users + mnapmf.num_items\n",
      "np.transpose(np.triu_indices(mnapmf.latent_d)) \\\n",
      "    [250 - n_useritems * mnapmf.latent_d - n_useritems * (n_useritems + 1) // 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([0, 0])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist((calc - approx)[calc != 0] / calc[calc != 0], log=True, bins=50)\n",
      "None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEBCAYAAACT92m7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJb/A2LivaryAFkKAAAAAElFTkSuQmCC\n"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_mean, c_cov_useritems, c_cov_latents = unstack_mn_kl(calc, mnapmf.num_users+mnapmf.num_items, mnapmf.latent_d)\n",
      "a_mean, a_cov_useritems, a_cov_latents = unstack_mn_kl(approx, mnapmf.num_users+mnapmf.num_items, mnapmf.latent_d)\n",
      "np.dstack((a_cov_latents, c_cov_latents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([[[  29248.43359375,  115653.41222713],\n",
        "        [ -22837.59375   ,  -22837.59416095]],\n",
        "\n",
        "       [[ -22837.59375   ,  -22837.59416095],\n",
        "        [   9126.04296875,   31558.51833908]]])"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "20*1 + 20 * 21 // 2 + 1 * 2 // 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "231"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}